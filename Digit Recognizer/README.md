# Intro

Kaggle's "Digit Recognizer" (https://www.kaggle.com/c/digit-recognizer) dataset is used explore and compare classification techniques, namely decision trees (DT), Naive Bayes (NB), k-nearest neighbors (kNN), support vector machine (SVM), and random forest (RF).

This core demonstration of this project was not only to construct the bones for the aforementioned methods but also to demonstrate that certain methods are better or worse than others, depending on the dataset. For example, the DT models required significant pruning for very minimal increases to an already low accuracy, whereas k-NN required modest pruning for to produce relatively high accuracy. The accuracies are assessed primarily through confusion matrices.

The original dataset is too large, so I've included a smaller version of each dataset used for training and testing.
